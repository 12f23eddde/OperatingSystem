##### 1. 总结虚拟页式管理机制，要求涵盖关键词

> 内存管理单元（MMU）、快表（TLB）、页面错误异常（Page Fault）、页表（多级页表、反转页表）、 页表项（PTE）、地址保护、放置策略（Placement）、 清除策略、置换策略（Replacement）、预取策略、驻留集/工作集。

###### 内存管理单元（MMU）

在多道程序编程中，我们不希望正在运行的程序访问其他程序的内存地址空间，程序员也不希望手动针对所有设备的内存空间进行适配。一个很自然的想法是，在编写程序时，程序员在代码内使用的是虚拟地址，在程序实际运行时将虚拟地址翻译成物理地址，由于一个用户程序的虚拟地址对应的物理地址不可能被其他程序占用，这就从根本上避免了用户程序访问其他应用程序的内存空间。我们固然可以使用软件进行间接寻址，然而这样的方案有一系列问题——无法做到对应用程序完全透明，软件较慢的运行速度也会对应用程序的访存效率造成相当不利的影响。因此，我们引入了硬件内存管理单元（MMU），间接寻址的过程在MMU内完成。

###### 页表

以字节这一最小访存单位对物理地址和虚拟地址进行映射固然可以，然而这会导致间接寻址的过程过于繁琐。因此我们选择以页为单位，将虚拟地址映射到物理地址。（在x86体系结构中，一页的大小默认是4KB）这样固然会造成一定的内碎片，不过在实际应用场景中大多数程序使用的内存都大于4KB，因此并不会造成什么问题。

为了存储虚拟地址和物理地址的映射关系，我们肯定需要设计一个数据结构，这就是页表。

###### 页表项（PTE）

页表中的每一项称为页表项。在这里我们先不考虑多级页表的情况，简单叙述一下地址翻译的过程：

当MMU获取一个虚拟地址之后，它会将虚拟地址拆分为VPN和Offset；MMU根据VPN从页表中找到对应的页表项，然后将页表项中的PPN和Offset拼接起来，得到物理地址。

###### 地址保护

当操作系统变得越来越复杂之后，我们意识到对应用程序的访存行为进行限制是很有必要的。既然系统的特权级分为用户态和内核态，我们就不能让用户态代码访问需要内核权限的内存空间。此外，我们也不能让程序轻易修改一些关键的内存数据，例如自身的代码段。因此，我们在页表项中增加一些权限位，MMU在进行地址翻译时会根据页表项中的权限位检查程序的访存行为是否合理，如果不合理则会抛出异常。

###### 多级页表

在计算机发展的早期，简单的页表暂时没有出现什么问题。然而当程序的地址空间扩大到$2^{32}$时，只采用一级页表进行地址翻译就会造成极大的空间开销。以x86体系结构为例，在极端情况下，一个用户程序的页表大小可以高达512GB，这显然是不可接受的。考虑到在一个进程的地址空间中，大多数的虚拟页并没有映射的物理页，我们可以不存储那些没有映射的页表项，从而显著减少内存占用。

采用多级页表之后，MMU会把VPN再进行一次拆分，分别拆分出一级页表、二级页表、……、n级页表的索引。MMU会根据一级页表的索引找出页表项中包含的页号，页号指向第二级页表的内存地址（这就要求页表的起始内存地址需要按页对齐），以此类推，最终在第n级页表中找到最终的PPN。如果写内存时对应的地址的某一级页表还不存在，则会在访存时为页表分配内存空间。

这里我们以x86-32的虚拟内存管理机制为例，阐述页表、页表项、地址保护、多级页表的概念：

32位的x86处理器采用二级页表来进行地址翻译。对于一个进程而言，大多数的虚拟页并没有映射的物理页，因此采用二级页表可以不存储那些没有映射的页表项，显著减少内存占用。x86处理器中默认的页大小是4KB，对应虚拟地址和物理地址中12位的Offset；物理地址的前20位对应物理内存中的页号，虚拟地址的前20位被拆成两个10位，分别对应第一级页表、第二级页表中的索引。

<img src="https://hehao98.github.io/assets/xv6-pic/pagetable.png" alt="figure2-1" style="zoom: 50%;" />

接下来我们来考虑地址翻译的过程。x86处理器中的虚拟内存管理硬件会从CR3寄存器中读出页目录的基地址，按照虚拟地址的前10位从页目录中的项中选出一项，读出页表的地址。如果这一项有效（P=1)，硬件会继续按照虚拟地址的中间10位从页表中选出页表项。否则，硬件则会抛出异常。

我们注意到一个页表项的大小是32bit，而其中PPN只占了20bit，剩下的12bit可以另作他用。页目录、页表中都存储了一些权限位（例如页是否有效、是否只读、是否允许用户访问等），页目录中还增加了PS位，表示这个页是一个4MB大页，不需要继续进行地址翻译（xv6的初始化过程包含对大页的使用）。如果当前的访存行为与权限位不匹配，硬件会抛出异常。

###### 反转页表

即使采用了多级页表后，页表所占据的内存空间依然与进程数量和进程的地址空间大小成正比。有没有办法进一步压缩页表占用的内存空间呢？这就出现了反转页表。

<img src="https://img-blog.csdnimg.cn/20191110103218405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODQxMTMw,size_16,color_FFFFFF,t_70" alt="img" style="zoom:50%;" />

在反转页表中，我们将物理内存地址映射到虚拟内存地址。由于每个进程的虚拟内存空间不同，我们需要在页表项中增加PID，表明映射到哪一个进程的虚拟内存地址。当我们进行地址翻译时，需要先在页表中查找符合当前访存PID和VPN的页表项，再根据页表项的索引确定PPN。这样操作系统中只存在一张页表，页表大小仅与物理内存大小成正比，尽可能地压缩了页表的大小。

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE3LmNuYmxvZ3MuY29tL2Jsb2cvMTE0NjE4My8yMDE3MTEvMTE0NjE4My0yMDE3MTEwODEyNDgzMTE2OS0xMDE2NTA3MjY0LnBuZw?x-oss-process=image/format,png" alt="img" style="zoom:50%;" />

然而对页表进行查找是一个相当花费时间的操作。页表中的PID是VPN是无序的，那查找操作的时间复杂度至少是$O(N)$。引入Hash表可以让查找时间得到极大的改善：在一般情况下，Hash表仅需要$O(1)$的时间就可以将VPN和PID映射到一个页表项。然而引入Hash表会带来新的问题——首先我们需要额外的内存空间存储Hash表，其次Hash不能保证（VPN，PID）$\rightarrow$ PTE 这一映射的唯一性，因此在这里采用开链法解决Hash冲突的问题。在页表项中，我们增加Next保存下一个Hash相同的页表项的索引，如果访存时发现Hash映射到的页表项与实际要访存的地址不匹配，就会按照Next顺着链表寻找。采用Hash表后，内存空间消耗大致增加了一倍，并且由于开链Hash在一些特殊情况下性能会退化到$O(N)$，因此需要一些机制，来避免应用程序构造特殊的访存序列使访存性能劣化的情况。

###### 页面错误异常（Page Fault）

在加载程序时一次性分配所有的内存空间显然不是一个好的选择。一方面我们需要在程序开始运行前预估它的内存消耗，另一方面会造成物理内存较低的实际使用率。因此我们可以参考JIT的思想，在装载应用程序时载入几个甚至零个页面，当实际访问这些页面时再将其载入物理内存。如果物理内存快满了，我们就把将来不大可能访问的页面换出到磁盘，从而腾出空间——这就是Lazy Load机制。

当程序访存时，MMU发现这个页面其实不在内存里（页表的有效位为0），就会触发一个Page Fault。异常处理程序会这样处理Page Fault：

1. 如果该页在磁盘中，从磁盘里载入；如果没有，则新建一个页。
2. 如果页表中有空闲的页表项，则将这一页表项分配给它，并修改对应的PPN、valid等位；如果页表中没有空闲的页表项，则置换一页，把置换掉的页表项分配给它。

###### 快表（TLB）

当现代处理器的执行速度变快，并引入多级页表之后，地址翻译过程的速度与处理器执行指令的速度产生了较大的差异。若每一次都访问内存并从内存中取出页表项，一次地址翻译可能需要花费数百个周期，这显然是不可接受的。考虑到程序访存行为的时间局部性原理（即程序访问过的内存地址很可能会接着访问），我们引入TLB作为页表的缓存。TLB项直接把VPN映射到PPN，如果在TLB中没有找到对应的VPN，MMU会访问内存，从内存中读出PPN，并将其放入TLB。

引入TLB之后，我们需要特别考虑TLB的内容是否与页表同步。我们可以选择在更改TLB项时同步更改页表，也可以选择当TLB项被换出或进程切换时一次性更改页表。

###### 预取策略

系统应该在什么时候把一个不在内存中的页面载入内存？

常见的策略有：

- 请求调页：在访存行为发生时载入页
- 预调页：预测访存行为，提前调入页

###### 置换策略（Replacement）

置换策略涉及两方面的问题：

1. 系统向物理内存中加载页时需要寻找一个空闲页表项，应该在什么范围内寻找空闲页表项？
2. 系统发现没有空闲页表项，需要换出一个页以分配新页时，应该按照什么标准选择这个被换出的页？

针对第一个问题，存在两种策略：

- 局部置换策略：仅在产生本次缺页的进程的驻留集中选择 

- 全局置换策略：将内存中所有未锁定的页框都作为置换的候选

第二个问题的本质就是寻找一个用于置换的算法。常见的算法有：

- 最近最少使用置换算法（LRU）

- 先进先出置换算法（FIFO）

- 时钟置换算法（Clock）

###### 放置策略（Placement）

系统应当在内存的什么位置为活跃进程分配页框？

对于一般的计算机而言，这一问题无关紧要，因为在内存的任何位置分配页，访存速度不会有太大的差别。但在特殊的情况下，例如NUMA系统，需要考虑处理器与内存的亲和以提升访存效率。

###### 清除策略

系统应该在什么时候将被置换的页写入磁盘？

常见的策略有：

- 请求清除策略：当一个页被置换时，若这个页被修改，立即写入外存。

- 页缓冲技术：将被置换的页放在内存的一个缓冲区中，多个被置换的页一次性以簇方式写回磁盘。

###### 驻留集/工作集

**工作集$W(t，Δ)$** 该进程在过去的$Δ$个虚拟时间单位中使用的虚拟页面集合，是进程在运行过程中固有的性质。

**驻留集** 当前时刻，进程实际驻留在内存当中的页框集合，取决于系统分配给进程的页框数和页面置换算法。

只有当一个进程的工作集在内存中时，才可以更好地执行该进程，即进程的驻留集包括了它的工作集。因此一个较好的页面置换算法应该监视每个进程的工作集，并周期性地从一个进程的驻留集中移去那些不在它的工作集中的页。

##### 2. 某64位计算机，虚拟地址空间为$2^{48}$，页面大小4K， 物理内存大小4G。分析对比：采用基于Hash表的反转页表比普通页表节省了多少空间？

我们暂时不考虑多级页表的情况。对于64位计算机，一个页表项大小为8B，在虚拟地址中，VPN占36位，Offset占12位。

###### 普通页表

对于一个进程而言，最多存在$2^{36}$个页表项，页表占用空间为$2^{29}$KB。

###### 基于Hash表的反转页表

采用基于Hash表的反转页表，则最多存在$2^{20}$个页表项。采用Hash之后的反转页表中含有VPN（36bit），Next (20bit)，这里我们还认为每一项大小是8B。

我们不知道Hash表有几项，这里暂且认为Hash表大小约为$2^{20}$项，每一项大小为4B。

总大小为$2^{20}*(4+8)B=1.5*2^{13}$KB。节省的空间约为512GB。

##### 3. 考虑一个进程的页访问序列，工作集为M页框，最初都是空的。页访问串的长度为P，包含N个不同的页号。对任何一种页面置换算法

###### 缺页中断次数的下限是多少？

$M \geq N$ 我们将工作集中所有的页都放入驻留集中，那么缺页次数就是$N$。

$M < N$ 我们构造序列，先访问在$M$内的页，最后再访问页号$p \in N-M$的页，这样触发缺页的次数就是$N$。

综上所述，缺页次数的下限是$N$。

###### 缺页中断次数的上限是多少？

对于合理的页面置换算法而言，其肯定能够占满M个物理页之后再进行替换。在占满$M$个物理页后，我们构造一个序列，使每一次访问的页号 $p \in N-M$，（在FIFO算法中可能会出现类似的情况），这样每一次访问就会触发一次缺页，中断次数的上限是$P$。

##### 4. 在论述一种页面置换算法时，有位作者用在循环轨道上来回移动的雪犁机来模拟说明：雪均匀地落在轨道上，雪犁机以恒定的速度在轨道上不断地循环，轨道上被扫落的雪从系统中消失。 

###### 哪种页面置换算法可以它来模拟？

时钟算法。

###### 这一模拟说明了页面置换算法的哪些行为？

**雪均匀地落在轨道上** 时钟算法遍历所有候选页表项。

**雪犁机以恒定的速度在轨道上不断地循环** 时钟算法从当前指针位置开始，循环查找use位为0的页表项。

**轨道上被扫落的雪从系统中消失** 遍历过的页表项的use位被改为0。

##### 5. 简要你对讨论mmap的理解

> 阅读（但不限于）以下文章： ① https://blog.csdn.net/joejames/article/details/37958017  Linux内存映射mmap原理分析
> ② https://www.jianshu.com/p/eece39beee20 深入剖析mmap原理 - 从三个关键问题说起

###### 当我们调用mmap()时，发生了什么？

mmap，顾名思义，就是Memory Map，也就是将文件映射到内存空间中。当我们使用mmap时，系统调用会返回一个指针ptr，指向虚拟内存空间中的一个区域。在这个过程中进程的虚拟内存空间中的一个区域被映射到了文件，建立并初始化了相关的数据结构`struct address_space`，然而实际上文件没有被载入内存，只是逻辑上被放入了内存。这一思想类似于我们实现的Lazy Load，因为我们不大可能一次性访问整个文件的内容，因此只有当我们当访问到某一个页时这个页才会被载入内存。

<img src="https://upload-images.jianshu.io/upload_images/12605489-b5b0f3d90c6baa8f.png" alt="img" style="zoom: 33%;" />

###### 为什么mmap的效率比read/write高？

首先我们需要说明当我们访问虚拟内存空间中文件对应的页时发生了什么。

当我们新访问一个页时，页表里显然不存在文件对应的页，因此会触发缺页异常。缺页异常处理函数首先会尝试在swap中寻找这个页，如果还是找不到，则会根据mmap建立的数据结构从磁盘中载入这个页。如果我们不小心用完了全部的物理内存，操作系统的虚拟内存管理机制自然会将不用的页放进swap，并不会出现什么问题。

read/write是系统调用调用，我们执行read/write时，需要先将磁盘上的数据读入内核中的缓冲区，再读入用户空间的内存，也就是需要两次拷贝。而处理缺页中断时，缺页异常处理函数会将磁盘中的数据直接读入用户内存空间，只需要一次拷贝。因此mmap的效率高于read/write。

###### mmap那些神秘的模式是干嘛用的？

**MAP_SHARED** 写入/更新数据时，会回写文件。如果有页被置换出内存，数据会被回写磁盘再淘汰，因此即使对数据的修改量远超内存大小，也不会出现什么问题。

**MAP_PRIVATE** 写入/更新数据时，会根据Copy On Write原则临时创建一份原始数据的副本，而副本是不会回写原文件的。如果我们不主动释放内存，有可能会出现Out of Memory。

**MAP_ANONYMOUS** 将内存空间映射到一个内核创建的匿名文件，存放于物理内存中。 写入/更新数据时，如果我们不主动释放内存，有可能会出现Out of Memory。

##### 参考资料

[Inverted Page Tables, TLBs](http://web.eecs.umich.edu/~akamil/teaching/sp04/040104.pdf)

[操作系统常用概念](https://blog.csdn.net/liu_sheng_no_one/article/details/7175996)